{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyTCVWbLuJrS",
        "outputId": "f3894463-378d-4308-cb34-f7798b68dc2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "____\n",
            "The Tokenizer is a necessary and pervasive component of Large Language Models (LLMs), where it translates between strings and tokens (text chunks). Tokenizers are a completely separate stage of the LLM pipeline: they have their own training sets, training algorithms (Byte Pair Encoding), and after training implement two fundamental functions: encode() from strings to tokens, and decode() back from tokens to strings. In this lecture we build from scratch the Tokenizer used in the GPT series from OpenAI. In the process, we will see that a lot of weird behaviors and problems of LLMs actually trace back to tokenization. We'll go through a number of these issues, discuss why tokenization is at fault, and why someone out there ideally finds a way to delete this stage entirely.\n",
            "length 781\n",
            "___\n",
            "[84, 104, 101, 32, 84, 111, 107, 101, 110, 105, 122, 101, 114, 32, 105, 115, 32, 97, 32, 110, 101, 99, 101, 115, 115, 97, 114, 121, 32, 97, 110, 100, 32, 112, 101, 114, 118, 97, 115, 105, 118, 101, 32, 99, 111, 109, 112, 111, 110, 101, 110, 116, 32, 111, 102, 32, 76, 97, 114, 103, 101, 32, 76, 97, 110, 103, 117, 97, 103, 101, 32, 77, 111, 100, 101, 108, 115, 32, 40, 76, 76, 77, 115, 41, 44, 32, 119, 104, 101, 114, 101, 32, 105, 116, 32, 116, 114, 97, 110, 115, 108, 97, 116, 101, 115, 32, 98, 101, 116, 119, 101, 101, 110, 32, 115, 116, 114, 105, 110, 103, 115, 32, 97, 110, 100, 32, 116, 111, 107, 101, 110, 115, 32, 40, 116, 101, 120, 116, 32, 99, 104, 117, 110, 107, 115, 41, 46, 32, 84, 111, 107, 101, 110, 105, 122, 101, 114, 115, 32, 97, 114, 101, 32, 97, 32, 99, 111, 109, 112, 108, 101, 116, 101, 108, 121, 32, 115, 101, 112, 97, 114, 97, 116, 101, 32, 115, 116, 97, 103, 101, 32, 111, 102, 32, 116, 104, 101, 32, 76, 76, 77, 32, 112, 105, 112, 101, 108, 105, 110, 101, 58, 32, 116, 104, 101, 121, 32, 104, 97, 118, 101, 32, 116, 104, 101, 105, 114, 32, 111, 119, 110, 32, 116, 114, 97, 105, 110, 105, 110, 103, 32, 115, 101, 116, 115, 44, 32, 116, 114, 97, 105, 110, 105, 110, 103, 32, 97, 108, 103, 111, 114, 105, 116, 104, 109, 115, 32, 40, 66, 121, 116, 101, 32, 80, 97, 105, 114, 32, 69, 110, 99, 111, 100, 105, 110, 103, 41, 44, 32, 97, 110, 100, 32, 97, 102, 116, 101, 114, 32, 116, 114, 97, 105, 110, 105, 110, 103, 32, 105, 109, 112, 108, 101, 109, 101, 110, 116, 32, 116, 119, 111, 32, 102, 117, 110, 100, 97, 109, 101, 110, 116, 97, 108, 32, 102, 117, 110, 99, 116, 105, 111, 110, 115, 58, 32, 101, 110, 99, 111, 100, 101, 40, 41, 32, 102, 114, 111, 109, 32, 115, 116, 114, 105, 110, 103, 115, 32, 116, 111, 32, 116, 111, 107, 101, 110, 115, 44, 32, 97, 110, 100, 32, 100, 101, 99, 111, 100, 101, 40, 41, 32, 98, 97, 99, 107, 32, 102, 114, 111, 109, 32, 116, 111, 107, 101, 110, 115, 32, 116, 111, 32, 115, 116, 114, 105, 110, 103, 115, 46, 32, 73, 110, 32, 116, 104, 105, 115, 32, 108, 101, 99, 116, 117, 114, 101, 32, 119, 101, 32, 98, 117, 105, 108, 100, 32, 102, 114, 111, 109, 32, 115, 99, 114, 97, 116, 99, 104, 32, 116, 104, 101, 32, 84, 111, 107, 101, 110, 105, 122, 101, 114, 32, 117, 115, 101, 100, 32, 105, 110, 32, 116, 104, 101, 32, 71, 80, 84, 32, 115, 101, 114, 105, 101, 115, 32, 102, 114, 111, 109, 32, 79, 112, 101, 110, 65, 73, 46, 32, 73, 110, 32, 116, 104, 101, 32, 112, 114, 111, 99, 101, 115, 115, 44, 32, 119, 101, 32, 119, 105, 108, 108, 32, 115, 101, 101, 32, 116, 104, 97, 116, 32, 97, 32, 108, 111, 116, 32, 111, 102, 32, 119, 101, 105, 114, 100, 32, 98, 101, 104, 97, 118, 105, 111, 114, 115, 32, 97, 110, 100, 32, 112, 114, 111, 98, 108, 101, 109, 115, 32, 111, 102, 32, 76, 76, 77, 115, 32, 97, 99, 116, 117, 97, 108, 108, 121, 32, 116, 114, 97, 99, 101, 32, 98, 97, 99, 107, 32, 116, 111, 32, 116, 111, 107, 101, 110, 105, 122, 97, 116, 105, 111, 110, 46, 32, 87, 101, 39, 108, 108, 32, 103, 111, 32, 116, 104, 114, 111, 117, 103, 104, 32, 97, 32, 110, 117, 109, 98, 101, 114, 32, 111, 102, 32, 116, 104, 101, 115, 101, 32, 105, 115, 115, 117, 101, 115, 44, 32, 100, 105, 115, 99, 117, 115, 115, 32, 119, 104, 121, 32, 116, 111, 107, 101, 110, 105, 122, 97, 116, 105, 111, 110, 32, 105, 115, 32, 97, 116, 32, 102, 97, 117, 108, 116, 44, 32, 97, 110, 100, 32, 119, 104, 121, 32, 115, 111, 109, 101, 111, 110, 101, 32, 111, 117, 116, 32, 116, 104, 101, 114, 101, 32, 105, 100, 101, 97, 108, 108, 121, 32, 102, 105, 110, 100, 115, 32, 97, 32, 119, 97, 121, 32, 116, 111, 32, 100, 101, 108, 101, 116, 101, 32, 116, 104, 105, 115, 32, 115, 116, 97, 103, 101, 32, 101, 110, 116, 105, 114, 101, 108, 121, 46]\n",
            "length 781\n"
          ]
        }
      ],
      "source": [
        "text = \"The Tokenizer is a necessary and pervasive component of Large Language Models (LLMs), where it translates between strings and tokens (text chunks). Tokenizers are a completely separate stage of the LLM pipeline: they have their own training sets, training algorithms (Byte Pair Encoding), and after training implement two fundamental functions: encode() from strings to tokens, and decode() back from tokens to strings. In this lecture we build from scratch the Tokenizer used in the GPT series from OpenAI. In the process, we will see that a lot of weird behaviors and problems of LLMs actually trace back to tokenization. We'll go through a number of these issues, discuss why tokenization is at fault, and why someone out there ideally finds a way to delete this stage entirely.\"\n",
        "tokens = text.encode('utf-8')\n",
        "tokens = list(map(int, tokens))\n",
        "\n",
        "print('____')\n",
        "print(text)\n",
        "print('length', len(text))\n",
        "print('___')\n",
        "print(tokens)\n",
        "print('length', len(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chr(84),chr(104)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-E_jGtyIu64",
        "outputId": "996bca24-dbab-48e0-84df-a639e0f3e653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('T', 'h')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tdWOQYqnIyw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stats(ids):\n",
        "    counts = {}\n",
        "    for pair in  zip(ids, ids[1:]):\n",
        "        counts[pair] = counts.get(pair,0) + 1\n",
        "    return counts\n",
        "\n",
        "stats  = get_stats(tokens)\n",
        "print(stats)\n",
        "\n",
        "##print(sorted(((v,k) for k, v in stats.items()), reverse=True))"
      ],
      "metadata": {
        "id": "HImhlX5Jxarv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc917f28-24c4-47cd-9375-cccb61be0771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(84, 104): 1, (104, 101): 10, (101, 32): 24, (32, 84): 3, (84, 111): 3, (111, 107): 8, (107, 101): 8, (101, 110): 15, (110, 105): 8, (105, 122): 5, (122, 101): 3, (101, 114): 9, (114, 32): 6, (32, 105): 7, (105, 115): 6, (115, 32): 18, (32, 97): 16, (97, 32): 5, (32, 110): 2, (110, 101): 4, (101, 99): 3, (99, 101): 3, (101, 115): 6, (115, 115): 4, (115, 97): 1, (97, 114): 4, (114, 121): 1, (121, 32): 8, (97, 110): 8, (110, 100): 8, (100, 32): 9, (32, 112): 4, (112, 101): 3, (114, 118): 1, (118, 97): 1, (97, 115): 1, (115, 105): 1, (105, 118): 1, (118, 101): 2, (32, 99): 3, (99, 111): 5, (111, 109): 7, (109, 112): 3, (112, 111): 1, (111, 110): 5, (110, 116): 4, (116, 32): 8, (32, 111): 7, (111, 102): 5, (102, 32): 5, (32, 76): 4, (76, 97): 2, (114, 103): 1, (103, 101): 4, (110, 103): 8, (103, 117): 1, (117, 97): 2, (97, 103): 3, (32, 77): 1, (77, 111): 1, (111, 100): 4, (100, 101): 6, (101, 108): 5, (108, 115): 1, (32, 40): 3, (40, 76): 1, (76, 76): 3, (76, 77): 3, (77, 115): 2, (115, 41): 2, (41, 44): 2, (44, 32): 7, (32, 119): 8, (119, 104): 3, (114, 101): 5, (105, 116): 2, (32, 116): 27, (116, 114): 8, (114, 97): 7, (110, 115): 5, (115, 108): 1, (108, 97): 1, (97, 116): 7, (116, 101): 7, (32, 98): 5, (98, 101): 3, (101, 116): 4, (116, 119): 2, (119, 101): 4, (101, 101): 2, (110, 32): 6, (32, 115): 11, (115, 116): 5, (114, 105): 5, (105, 110): 13, (103, 115): 3, (116, 111): 9, (40, 116): 1, (101, 120): 1, (120, 116): 1, (99, 104): 2, (104, 117): 1, (117, 110): 3, (110, 107): 1, (107, 115): 1, (41, 46): 1, (46, 32): 4, (114, 115): 2, (112, 108): 2, (108, 101): 5, (108, 121): 4, (115, 101): 6, (101, 112): 1, (112, 97): 1, (116, 97): 3, (116, 104): 13, (77, 32): 1, (112, 105): 1, (105, 112): 1, (108, 105): 1, (101, 58): 1, (58, 32): 2, (101, 121): 1, (32, 104): 1, (104, 97): 3, (97, 118): 2, (101, 105): 2, (105, 114): 4, (111, 119): 1, (119, 110): 1, (97, 105): 4, (103, 32): 3, (116, 115): 1, (115, 44): 4, (97, 108): 4, (108, 103): 1, (103, 111): 2, (111, 114): 2, (104, 109): 1, (109, 115): 2, (40, 66): 1, (66, 121): 1, (121, 116): 1, (32, 80): 1, (80, 97): 1, (32, 69): 1, (69, 110): 1, (110, 99): 3, (100, 105): 2, (103, 41): 1, (97, 102): 1, (102, 116): 1, (105, 109): 1, (101, 109): 2, (109, 101): 3, (119, 111): 1, (111, 32): 6, (32, 102): 8, (102, 117): 2, (100, 97): 1, (97, 109): 1, (108, 32): 3, (99, 116): 3, (116, 105): 4, (105, 111): 4, (115, 58): 1, (32, 101): 2, (101, 40): 2, (40, 41): 2, (41, 32): 2, (102, 114): 4, (114, 111): 7, (109, 32): 4, (32, 100): 3, (98, 97): 2, (97, 99): 4, (99, 107): 2, (107, 32): 2, (115, 46): 1, (32, 73): 2, (73, 110): 2, (104, 105): 2, (32, 108): 2, (116, 117): 2, (117, 114): 1, (98, 117): 1, (117, 105): 1, (105, 108): 2, (108, 100): 1, (115, 99): 2, (99, 114): 1, (116, 99): 1, (104, 32): 2, (32, 117): 1, (117, 115): 2, (101, 100): 1, (32, 71): 1, (71, 80): 1, (80, 84): 1, (84, 32): 1, (105, 101): 1, (32, 79): 1, (79, 112): 1, (110, 65): 1, (65, 73): 1, (73, 46): 1, (112, 114): 2, (111, 99): 1, (119, 105): 1, (108, 108): 4, (108, 111): 1, (111, 116): 1, (114, 100): 1, (101, 104): 1, (118, 105): 1, (111, 98): 1, (98, 108): 1, (122, 97): 2, (110, 46): 1, (32, 87): 1, (87, 101): 1, (101, 39): 1, (39, 108): 1, (32, 103): 1, (104, 114): 1, (111, 117): 2, (117, 103): 1, (103, 104): 1, (110, 117): 1, (117, 109): 1, (109, 98): 1, (115, 117): 1, (117, 101): 1, (99, 117): 1, (104, 121): 2, (102, 97): 1, (97, 117): 1, (117, 108): 1, (108, 116): 1, (116, 44): 1, (115, 111): 1, (101, 111): 1, (117, 116): 1, (105, 100): 1, (101, 97): 1, (102, 105): 1, (100, 115): 1, (119, 97): 1, (97, 121): 1, (121, 46): 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EGykEGzfHku_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_pair = max(stats, key=stats.get)\n",
        "top_pair"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOBe_igIuPYC",
        "outputId": "966ae858-7ed3-4042-a9e7-8005087abf2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 116)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def merge(ids, pair, idx):\n",
        "  newids = []\n",
        "  i=0\n",
        "  while i < len(ids):\n",
        "    if i<len(ids)-1 and ids[i]== pair[0] and ids[i+1] == pair[1]:\n",
        "      newids.append(idx)\n",
        "      i+=2\n",
        "    else:\n",
        "      newids.append(ids[i])\n",
        "      i+=1\n",
        "  return newids\n",
        "\n",
        "print(merge([5,6,6,7,9,1], (6,7), 99))\n",
        "tokens2 = merge(tokens, top_pair, 256)\n",
        "print(tokens2)\n",
        "print('length', len(tokens2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24j51miLCYKC",
        "outputId": "b33dd239-b29f-4676-f969-400e3fd7275a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 6, 99, 9, 1]\n",
            "[84, 104, 101, 32, 84, 111, 107, 101, 110, 105, 122, 101, 114, 32, 105, 115, 32, 97, 32, 110, 101, 99, 101, 115, 115, 97, 114, 121, 32, 97, 110, 100, 32, 112, 101, 114, 118, 97, 115, 105, 118, 101, 32, 99, 111, 109, 112, 111, 110, 101, 110, 116, 32, 111, 102, 32, 76, 97, 114, 103, 101, 32, 76, 97, 110, 103, 117, 97, 103, 101, 32, 77, 111, 100, 101, 108, 115, 32, 40, 76, 76, 77, 115, 41, 44, 32, 119, 104, 101, 114, 101, 32, 105, 116, 256, 114, 97, 110, 115, 108, 97, 116, 101, 115, 32, 98, 101, 116, 119, 101, 101, 110, 32, 115, 116, 114, 105, 110, 103, 115, 32, 97, 110, 100, 256, 111, 107, 101, 110, 115, 32, 40, 116, 101, 120, 116, 32, 99, 104, 117, 110, 107, 115, 41, 46, 32, 84, 111, 107, 101, 110, 105, 122, 101, 114, 115, 32, 97, 114, 101, 32, 97, 32, 99, 111, 109, 112, 108, 101, 116, 101, 108, 121, 32, 115, 101, 112, 97, 114, 97, 116, 101, 32, 115, 116, 97, 103, 101, 32, 111, 102, 256, 104, 101, 32, 76, 76, 77, 32, 112, 105, 112, 101, 108, 105, 110, 101, 58, 256, 104, 101, 121, 32, 104, 97, 118, 101, 256, 104, 101, 105, 114, 32, 111, 119, 110, 256, 114, 97, 105, 110, 105, 110, 103, 32, 115, 101, 116, 115, 44, 256, 114, 97, 105, 110, 105, 110, 103, 32, 97, 108, 103, 111, 114, 105, 116, 104, 109, 115, 32, 40, 66, 121, 116, 101, 32, 80, 97, 105, 114, 32, 69, 110, 99, 111, 100, 105, 110, 103, 41, 44, 32, 97, 110, 100, 32, 97, 102, 116, 101, 114, 256, 114, 97, 105, 110, 105, 110, 103, 32, 105, 109, 112, 108, 101, 109, 101, 110, 116, 256, 119, 111, 32, 102, 117, 110, 100, 97, 109, 101, 110, 116, 97, 108, 32, 102, 117, 110, 99, 116, 105, 111, 110, 115, 58, 32, 101, 110, 99, 111, 100, 101, 40, 41, 32, 102, 114, 111, 109, 32, 115, 116, 114, 105, 110, 103, 115, 256, 111, 256, 111, 107, 101, 110, 115, 44, 32, 97, 110, 100, 32, 100, 101, 99, 111, 100, 101, 40, 41, 32, 98, 97, 99, 107, 32, 102, 114, 111, 109, 256, 111, 107, 101, 110, 115, 256, 111, 32, 115, 116, 114, 105, 110, 103, 115, 46, 32, 73, 110, 256, 104, 105, 115, 32, 108, 101, 99, 116, 117, 114, 101, 32, 119, 101, 32, 98, 117, 105, 108, 100, 32, 102, 114, 111, 109, 32, 115, 99, 114, 97, 116, 99, 104, 256, 104, 101, 32, 84, 111, 107, 101, 110, 105, 122, 101, 114, 32, 117, 115, 101, 100, 32, 105, 110, 256, 104, 101, 32, 71, 80, 84, 32, 115, 101, 114, 105, 101, 115, 32, 102, 114, 111, 109, 32, 79, 112, 101, 110, 65, 73, 46, 32, 73, 110, 256, 104, 101, 32, 112, 114, 111, 99, 101, 115, 115, 44, 32, 119, 101, 32, 119, 105, 108, 108, 32, 115, 101, 101, 256, 104, 97, 116, 32, 97, 32, 108, 111, 116, 32, 111, 102, 32, 119, 101, 105, 114, 100, 32, 98, 101, 104, 97, 118, 105, 111, 114, 115, 32, 97, 110, 100, 32, 112, 114, 111, 98, 108, 101, 109, 115, 32, 111, 102, 32, 76, 76, 77, 115, 32, 97, 99, 116, 117, 97, 108, 108, 121, 256, 114, 97, 99, 101, 32, 98, 97, 99, 107, 256, 111, 256, 111, 107, 101, 110, 105, 122, 97, 116, 105, 111, 110, 46, 32, 87, 101, 39, 108, 108, 32, 103, 111, 256, 104, 114, 111, 117, 103, 104, 32, 97, 32, 110, 117, 109, 98, 101, 114, 32, 111, 102, 256, 104, 101, 115, 101, 32, 105, 115, 115, 117, 101, 115, 44, 32, 100, 105, 115, 99, 117, 115, 115, 32, 119, 104, 121, 256, 111, 107, 101, 110, 105, 122, 97, 116, 105, 111, 110, 32, 105, 115, 32, 97, 116, 32, 102, 97, 117, 108, 116, 44, 32, 97, 110, 100, 32, 119, 104, 121, 32, 115, 111, 109, 101, 111, 110, 101, 32, 111, 117, 116, 256, 104, 101, 114, 101, 32, 105, 100, 101, 97, 108, 108, 121, 32, 102, 105, 110, 100, 115, 32, 97, 32, 119, 97, 121, 256, 111, 32, 100, 101, 108, 101, 116, 101, 256, 104, 105, 115, 32, 115, 116, 97, 103, 101, 32, 101, 110, 116, 105, 114, 101, 108, 121, 46]\n",
            "length 754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gScsnECuzKwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q_nnIyDRrQa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IFiFu4U-1BhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vocab_size = 276\n",
        "num_merges = vocab_size - 256\n",
        "ids = list(tokens)\n",
        "\n",
        "merges = {}\n",
        "for i in range(num_merges):\n",
        "    stats = get_stats(ids)\n",
        "    pair = max(stats, key=stats.get)\n",
        "    idx = 256 + i\n",
        "    print(f\"merging {pair} into a new token {idx}\")\n",
        "    ids = merge(ids,pair,idx)\n",
        "    merges[pair] = idx\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhvWYFs6rQk0",
        "outputId": "40799986-52a8-4757-b535-50600e50c7f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "merging (32, 116) into a new token 256\n",
            "merging (101, 32) into a new token 257\n",
            "merging (115, 32) into a new token 258\n",
            "merging (101, 110) into a new token 259\n",
            "merging (105, 110) into a new token 260\n",
            "merging (256, 104) into a new token 261\n",
            "merging (101, 114) into a new token 262\n",
            "merging (32, 115) into a new token 263\n",
            "merging (256, 111) into a new token 264\n",
            "merging (107, 259) into a new token 265\n",
            "merging (32, 97) into a new token 266\n",
            "merging (258, 97) into a new token 267\n",
            "merging (110, 100) into a new token 268\n",
            "merging (111, 109) into a new token 269\n",
            "merging (114, 97) into a new token 270\n",
            "merging (260, 103) into a new token 271\n",
            "merging (32, 102) into a new token 272\n",
            "merging (100, 101) into a new token 273\n",
            "merging (265, 105) into a new token 274\n",
            "merging (274, 122) into a new token 275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tokens length:\", len(tokens))\n",
        "print(\"ids length\", len(ids ))\n",
        "print(f\"compression ratio: {len(tokens)/ len(ids):.2f}X\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxSKw-q12-eG",
        "outputId": "9f01f6cc-9dcc-4e40-f9fa-411242fb796f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens length: 781\n",
            "ids length 576\n",
            "compression ratio: 1.36X\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##decode"
      ],
      "metadata": {
        "id": "7bxUDTGA2-hK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "136XxATcYMne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RmOTwPR1cL_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7KBxapHMcMIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {idx: bytes([idx]) for idx in range(256)}\n",
        "for (p0, p1) , idx in merges.items():\n",
        "  vocab[idx] = vocab[p0]  + vocab[p1]\n",
        "\n",
        "def decode(ids):\n",
        "  tokens = b\"\".join(vocab[idx] for idx in ids)\n",
        "  text = tokens.decode('latin-1')\n",
        "\n",
        "\n",
        "  return text\n",
        "\n",
        "print(decode([201]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ii179dq2-kU",
        "outputId": "a7cfedf1-e1e4-4d5c-8701-aa62e28acb23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ã‰\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text):\n",
        "\n",
        "  tokens = list(text.encode('utf-8'))\n",
        "  while len(tokens) >= 2:\n",
        "    stats= get_stats(tokens)\n",
        "    pair = min(stats, key=lambda p: merges.get(p, float('inf')))\n",
        "    if pair not in merges:\n",
        "      break\n",
        "\n",
        "      idx = merges[pair]\n",
        "      tokens = merge(tokens, pair, idx)\n",
        "  return tokens\n",
        "\n",
        "print(encode(\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoqdMJU5cNem",
        "outputId": "9b42eab5-f41d-4da7-8c25-e516a361968c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(encode('hello world')))"
      ],
      "metadata": {
        "id": "vdJcOtGqcNhN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d3b8d9-21e3-4948-c6b6-f9ba2de1e38f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uV7yNDq0upKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = decode(encode(text))\n",
        "print(text2 == text)"
      ],
      "metadata": {
        "id": "uk9yBTkEvr9Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}